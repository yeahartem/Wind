{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from src.data_utils import data_processing as dp\n",
    "from src.data_utils.data_processing import make_model_dataset\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dss(start_date, end_date, station_name, station_list, ds_for_y, delta_in_x, include_day_ohe=False, speed_th=20, pix=[-1, -1]):\n",
    "    '''\n",
    "    Includes several days into X. Makes dataset consisting of X from make_model_dataset(weatherstation_list.csv) and y from data_meteo_kk.csv.\n",
    "    \n",
    "    station_list - weatherstation_list.csv,\n",
    "    ds_for_y - data_meteo_kk.csv,\n",
    "    delta_in_x - number of days into X.\n",
    "    '''\n",
    "    a = make_model_dataset(station_name = station_name, start_date = start_date, end_date = end_date, station_list = station_list, pix = pix)\n",
    "    a.insert(loc=0, column='day', value=a.index)\n",
    "    a['day'] = a['day'].dt.dayofyear\n",
    "\n",
    "    if include_day_ohe:\n",
    "        enc = OneHotEncoder()\n",
    "        enc.fit(np.array(a.day).reshape(-1, 1))\n",
    "        a.drop('day', axis=1, inplace=True)\n",
    "        lis = [\n",
    "            [\n",
    "                np.concatenate(\n",
    "                    (\n",
    "                        np.array(a.iloc[i-delta_in_x : i]).reshape(1, -1),\n",
    "                        enc.transform(\n",
    "                            np.atleast_2d(a.iloc[i-1].name.dayofyear)\n",
    "                        ).toarray(),\n",
    "                    ),\n",
    "                    axis=1,\n",
    "                )\n",
    "            ]\n",
    "            for i in range(delta_in_x, a.shape[0])\n",
    "        ]\n",
    "    else:\n",
    "        a.drop('day', axis=1, inplace=True)\n",
    "        lis = [\n",
    "            [\n",
    "                np.concatenate(\n",
    "                    (\n",
    "                        np.array(a.iloc[i-delta_in_x : i]).reshape(1, -1),\n",
    "                    ),\n",
    "                    axis=1,\n",
    "                )\n",
    "            ]\n",
    "            for i in range(delta_in_x, a.shape[0])\n",
    "        ]\n",
    "    \n",
    "    X = np.array(lis).reshape(np.array(lis).shape[0], -1)\n",
    "\n",
    "    ds_for_y['Дата'] = pd.to_datetime((ds_for_y['Дата']), format=\"%Y/%m/%d\")\n",
    "    ds_for_y = ds_for_y.loc[(ds_for_y['Дата'] >= pd.to_datetime(start_date)) & (ds_for_y['Дата'] <= pd.to_datetime(end_date))]\n",
    "    ds_for_y = ds_for_y.loc[ds_for_y['Название метеостанции'] == station_name]\n",
    "    ds_for_y = ds_for_y.groupby(ds_for_y['Дата']).max()   # Как группируется?\n",
    "    max_speed = ds_for_y[['Максимальная скорость', 'Средняя скорость ветра']].max(axis=1)\n",
    "    y = np.array((max_speed >= speed_th).astype(int))\n",
    "    y = y[delta_in_x:a.shape[0]]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(start_date, end_date, station_name, station_list, ds_for_y, include_day_ohe=False, speed_th=20):\n",
    "    '''\n",
    "    Makes dataset consisting of X from make_model_dataset(weatherstation_list.csv) and y from data_meteo_kk.csv.\n",
    "    \n",
    "    station_list - weatherstation_list.csv,\n",
    "    ds_for_y - data_meteo_kk.csv.\n",
    "    '''\n",
    "    a = make_model_dataset(station_name = station_name, start_date = start_date, end_date = end_date, station_list = station_list)\n",
    "    a.insert(loc=0, column='day', value=a.index)\n",
    "    a['day'] = a['day'].dt.dayofyear\n",
    "    \n",
    "    if include_day_ohe:\n",
    "        enc = OneHotEncoder()\n",
    "        enc.fit(np.array(a.day).reshape(-1, 1))\n",
    "        a.drop('day', axis=1, inplace=True)\n",
    "        lis = [[enc.transform(np.atleast_2d(a.iloc[i].name.dayofyear)).toarray()] for i in range(a.shape[0])]\n",
    "        ohe_day = pd.DataFrame(np.array(lis).reshape(np.array(lis).shape[0], -1))\n",
    "        X = pd.concat([a, ohe_day.set_index(a.index)], axis=1)\n",
    "    else:\n",
    "        a.drop('day', axis=1, inplace=True)\n",
    "        X = a\n",
    "    \n",
    "\n",
    "    # X = pd.concat([a, ohe_day.set_index(a.index)], axis=1)\n",
    "    \n",
    "\n",
    "    ds_for_y['Дата'] = pd.to_datetime((ds_for_y['Дата']), format=\"%Y/%m/%d\")\n",
    "    ds_for_y = ds_for_y.loc[(ds_for_y['Дата'] >= pd.to_datetime(start_date)) & (ds_for_y['Дата'] <= pd.to_datetime(end_date))]\n",
    "    ds_for_y = ds_for_y.loc[ds_for_y['Название метеостанции'] == station_name]\n",
    "    ds_for_y = ds_for_y.groupby(ds_for_y['Дата']).max()   # Как группируется?\n",
    "    max_speed = ds_for_y[['Максимальная скорость', 'Средняя скорость ветра']].max(axis=1)\n",
    "    y = np.array((max_speed >= speed_th).astype(int))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_shape():\n",
    "    path_to_history = 'data/history'\n",
    "    feature_name='tasmax'\n",
    "    file_paths = [path_to_history+ '/' + fn for fn in os.listdir(path_to_history) if (fn[-4:] == '.tif' ) and feature_name in fn]   \n",
    "    dataset = gdal.Open(file_paths[0], gdal.GA_ReadOnly)\n",
    "    \n",
    "    band = dataset.GetRasterBand(1)\n",
    "    \n",
    "    arr = band.ReadAsArray()\n",
    "    return arr.shape\n",
    "\n",
    "region_shape = get_region_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2006-01-01'\n",
    "end = '2020-01-01'\n",
    "df = pd.read_csv('data_meteo_kk.csv')\n",
    "st = pd.read_csv('weatherstation_list.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_day_ohe = False\n",
    "single_day = False\n",
    "speed_th = 20\n",
    "if 'pixelwise_X.pkl' not in os.listdir():\n",
    "    data_dict = {}\n",
    "    for i in tqdm(range(region_shape[0])):\n",
    "        for j in range(region_shape[1]):\n",
    "            X, _ = dss(start, end, None, st, df, 15, include_day_ohe=include_day_ohe, speed_th=speed_th, pix=[j, i])\n",
    "            data_dict[(i, j)] = X\n",
    "    filename = 'pixelwise_X.pkl'\n",
    "    pickle.dump(data_dict, open(filename, 'wb'))\n",
    "    loaded_dict = pickle.load(open(filename, 'rb'))\n",
    "    equals = True\n",
    "    for k in loaded_dict.keys():\n",
    "        equals = equals and np.allclose(loaded_dict[k], data_dict[k])\n",
    "    print(\"Saved correctly: \", equals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb9120d4e94f37695d2a45f521fb366896a7bc5eab844a4c6789236e8d913311"
  },
  "kernelspec": {
   "display_name": "Python 3.5.5 ('pygdal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
